# Skynet

## AI Use Cases

### AI Grading for Certification Tests (Aptitude Test 1)

- Implement AI to grade short answer questions based on an answer key.
- Provide candidates with an option to grade questions they are presented with for certification.
- Add a review process for graded answers to identify and address bad questions before sending email results.

### AI-Driven Analysis and Recommendations (Email The Results)

- Create a breakdown/analysis of test results using AI.
- Provide study topic recommendations based on analysis, potentially linking to resources like O'Reilly.

### Chatbot for FAQs (For UI, when pulling in the case study)

- Develop a chatbot to answer frequently asked questions based on a FAQ database.

### Case Study Solutions Management(Database for Case Study Solutions)

- Audit all added solutions for case studies.
- Add a process to include new solutions to the answer set for each case study, building a comprehensive set of possible solutions for AI reference.

### AI Grading Confidence and Automation (Short Answer Review)

- Implement AI grading with a confidence level value.
- Allow for quick expert review of AI-graded results based on confidence levels.
- Enable fully automated grading for high-confidence results, setting a threshold for automation.

### Plagiarism Detection (Case Study Solution)

- Integrate AI to check for plagiarism, ensuring candidates are not cheating.

### AI Review and Feedback on Test Reports (Admin - Aptitude Test Analysis Report )

- Use AI to review test reports and provide summaries with feedback on question relevance.
- Analyze both multiple-choice and short answer questions, as well as expert reviews.
- Automatically modify aptitude tests based on AI feedback, subject to review and approval by designated expert software architects.

### AI for Case Study Content Management(Admin - Modify Case Study and Grading Criteria)

- Use AI to read and modify existing case studies, improving grammar and suggesting new case studies based on current tech trends.
- Extract and create grading criteria from past expert reviews.

### AI Evaluation of Expert Grading(Admin - Adding/Maintaining Expert SA )

- Implement AI to grade experts on the accuracy, timeliness, and detail of their reviews.
- Gather feedback on expert accuracy from analyzed aptitude test reports.

### AI Observability

- Implement observability features to provide details on AI review accuracy.
- Make adjustments based on observations and feed them back into the model for continuous training.
- Build observability features to monitor AI cost, accuracy, bias, and time reduction/improvements.

### Feedback for New Case Studies

- Allow designated experts to send out surveys to other experts for feedback on new case studies.
- Use AI to review and summarize the feedback, aiding in the creation and modification of case studies.
